---
title: "Multiple Correspondance Analysis LAB"
output:
  html_document
---

```{r, warning=FALSE, echo=FALSE, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse)
pacman::p_load(FactoMineR)
pacman::p_load(factoextra)
pacman::p_load(FactoInvestigate)
pacman::p_load(ggmosaic)
pacman::p_load(ggrepel)
pacman::p_load(vcd)
pacman::p_load(assertthat)
pacman::p_load("fontawesome")
```



# Multiple Correspondance Analysis LAB


## Motivation: analyzing more than 2 categorical variables

```{r, echo=FALSE}

tit_col_types = cols(

  PassengerId = col_integer(),

  Survived = col_factor(levels=c("0", "1"),   #<<
                        include_na = TRUE),   #<<

  Pclass = col_factor(levels=c("1", "2", "3"),  #<<
                      ordered = TRUE,           #<<
                      include_na = TRUE),       #<<

  Sex = col_factor(levels = c("female", "male")),
  Age = col_double(),
  SibSp = col_integer(),
  Parch = col_integer(),

  Embarked = col_factor(levels = c("S", "C", "Q"),
                        include_na = TRUE)
)
train <- read_csv("DATA/titanic/train.csv",
          col_types=tit_col_types)
test <- read_csv("DATA/titanic/test.csv",
          col_types=tit_col_types)

test <- mutate(test, #<<
               Survived=NA)  #<<

tit <- union(train,
             test)

tit$Survived <- forcats::fct_recode(tit$Survived,      #<<
                                    "Deceased"="0",    #<<
                                    "Survived"="1") %>%   #<<
                          forcats::fct_relevel(c("Survived", "Deceased")) #<<

tit$Age <-
  cut(tit$Age,
      breaks = c(0, 18, 100),
      labels=c("Child", "Adult")) %>%
  fct_explicit_na("NA.A")


tit %>%
  select(Sex, Age, Embarked, Pclass) %>%
  head()
```

### `r fontawesome::fa("ship")` Mosaicplots for `n`-ways contingency tables


```{r, echo=TRUE}
vcd::mosaic(x=Titanic)
```


The interplay between the response variable `Survived` and the four explanatory variables  using
a naive mosaicplot is hard to spot

The global arrangement of tiles has a huge impact on the interpretability of multi-dimensional mosaicplots

Variants of mosaicplots like _double decker_ plots make the task easier


```{r}
tit %>%
  dplyr::select(Pclass, Embarked) %>%
  drop_na() %>%
  ggplot() +
  geom_mosaic(aes(x = product(Embarked, Pclass), fill=Embarked)) +
  labs(x= "Passenger class", y="Embarked") +
  scale_fill_viridis_d() +
  ggtitle("Titanic mosaic with tidyverse flavor")
```


In the Titanic table the four variables do have the same status:

- Class, Age, Sex may be considered as "demographic", or "explanatory"
- Survived is a "response" variable

When using variants of mosaicplot to investigate the Titanic dataset


## Variations on Mosaicplot

### Mosaic plots versus Association plots


> In order to explain multi-dimensional categorical data, statisticians typically look for (conditional) independence structures

> Whether the task is purely exploratory or model-based, techniques such as _mosaic_ and _association_ plots offer good support for visualization    [Structplot vignette]

Before turning back to Titanic dataset, let us revisit the `UCBAdmissions` dataset

Remember that
the `UCBAdmissions` dataset was elaborated in the 1970's to assess whether the admission process at the different departments of UC Berkeley   suffered from a gender bias

Such a possibility was suggested by looking at the global admission rate for female and male candidates


### `r fontawesome::fa("university")` Order matters


```{r, out.width="50%", fig.show='hold'}
aperm(UCBAdmissions, c(3, 2, 1)) %>% mosaicplot(shade=TRUE)

aperm(UCBAdmissions, c(3, 2, 1)) %>% vcd::mosaic(shade=TRUE)
```


Both diagrams are mosaicplots

The diagram on the right is easier to interpret: it provides a picture
of admission rates per department and then gender


### `r fontawesome::fa("university")` Double decker plot for  `UCBAdmissions`



```{r}
aperm(UCBAdmissions, c(3, 2, 1)) %>%
  vcd::doubledecker()
```

Double decker plots are special kinds of mosaicplots

- Per department admissions exhibit no clear bias against
women
- Men tend to fill more applications to less selective departments



[Simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)

> A trend appears in several different groups of data but disappears or reverses when these groups are combined

> This result is often encountered in social-science and medical-science statistics and is particularly problematic when frequency data is unduly given causal interpretations.

> The paradox is also referred to as Simpson's reversal, Yuleâ€“Simpson effect, amalgamation paradox, or reversal paradox

[Wikipedia]


A double decker plot is a collection of stacked column/bar plots: For each
department, we have a column plot where `Gender` is mapped to `x` and `Admit`
to `y`. Columns are stacked. Width is proportional to number of applicants
with given Gender for the department. Height is proportional to fraction
of successful/failing applicants for given  Department and Gender


```{r}
# dimnames(UCBAdmissions)
mantelhaen.test(UCBAdmissions)
```

```{r}
## UC Berkeley Student Admissions
mantelhaen.test(UCBAdmissions)
## No evidence for association between admission and gender
## when adjusted for department.  However,
apply(UCBAdmissions, 3, function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))
## This suggests that the assumption of homogeneous (conditional)
## odds ratios may be violated.  The traditional approach would be
## using the Woolf test for interaction:
woolf <- function(x) {
  x <- x + 1 / 2
  k <- dim(x)[3]
  or <- apply(x, 3, function(x) (x[1,1]*x[2,2])/(x[1,2]*x[2,1]))
  w <-  apply(x, 3, function(x) 1 / sum(1 / x))
  1 - pchisq(sum(w * (log(or) - weighted.mean(log(or), w)) ^ 2), k - 1)
}
woolf(UCBAdmissions)
## => p = 0.003, indicating that there is significant heterogeneity.
## (And hence the Mantel-Haenszel test cannot be used.)

```

### `r fontawesome::fa("ship")` Flattening the Titanic table


```{r, eval=FALSE}
pacman::p_load(xtable)
vcd::structable(~ Class + Age + Sex, aperm(Titanic, c(1,3,2, 4))) %>%
  xtable::xtableFtable()
```


Flattenig allows to organize information

Double decker plots allow to do this graphically


### `r fontawesome::fa("ship")` Double-decker plots for the Titanic data

```{r, out.width="50%", fig.show='hold'}
vcd::doubledecker(Titanic)

tit %>%
  filter(Survived %in% c('Survived', 'Deceased')) %>%
  filter(Age %in% c('Adult', 'Child')) %>%
  mutate(Age=fct_drop(Age)) %>%
  ggplot() +
  geom_mosaic(aes(x=product(Survived, Age, Sex, Pclass), fill=Survived), divider=ddecker()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  scale_fill_viridis_d()
```

`Titanic` is a base `r fontawesome::fa("r-project")` contingency table where `Pclass, Sex, Age, Survived` were cross-tabulated




##  `r fontawesome::fa("fingerprint")` Indicator matrices


### `r fontawesome::fa("binoculars")` Two perspectives

MCA can be viewed along two perspectives:

- Analyzing the dataset after performing _one-hot_ encoding of categorical variables: investigating the so-called _indicator_ matrix


- Analyzing all pairwise two-way contingency tables derived from the dataset: : investigating the so-called _Burt_ matrix


### A glimpse at the indicator matrix

Function `tab.disjonctif()` from `FactoMineR` builds an _indicator_ matrix starting
from  a dataframe with categorical columns

```{r}
Z <- tit %>%
  drop_na() %>%
  select(Sex, Age, Embarked, Pclass) %>%
  tab.disjonctif() #<<

Z %>% 
  head() %>% 
  knitr::kable()
```

`tab.disjonctif` is a shorthand for _tableau disjonctif complet_, the French name of indicator matrix

### Construction of indicator matrix

- A categorical variable $V_j$ (factor) with $q$ levels is mapped to $q$ $\{0,1\}$ -valued variables $V_{j,r}$ for $r \leq q$

- If levels are indexed by $\{1, \ldots, q\}$, if the value of the categorical variable $V_j$ from row $i$  is $k \in \{1, \ldots, q\}$, the binary variables $V_{j,r}$ on that row take values
$$k \mapsto \underbrace{0,\ldots, 0}_{k-1}, 1, \underbrace{0, \ldots, 0}_{q-k}$$

- In Machine Learning parlance building  the indicator matrix consists of performing _one-hot encoding_ for each categorical variable

- The indicator matrix has as many rows as the data matrix

- The number of columns of the indicator matrix is the sum of the number of levels of the categorical variables/columns of the data matrix

- The indicator matrix is a numerical matrix. It is suitable for factorial methods `r fontawesome::fa("smile")`




## MCA in words

[FactomineR on MCA](http://factominer.free.fr/factomethods/multiple-correspondence-analysis.html)

### MCA on `r fontawesome::fa("ship")` Titanic

`r fontawesome::fa("bullhorn")` MCA consists of performing CA (correspondance analysis)  on the _indicator matrix_


```{r, echo=TRUE}
res.mca <- tit %>% 
  drop_na() %>%
  select(Sex,
         Age,
         Embarked,
         Pclass) %>%
  MCA(graph = FALSE)      #<<
```

We perform MCA on the data matrix made from four similar qualitative  columns: `Sex`, `Age`, `Embarked`, `Pclass`


`res.mca` is a list with class attributes `MCA`  and `list`. It contains many related components

`r fontawesome::fa("hand-point-right")` Component `svd` of `res.mca$svd` can righteously be considered
as the most important part of the result

Other components are either byproducts of the computation of `res.mca$svd`
or derived from `res.mca$svd` so as to facilitate
reporting either numerical or graphical



### Output of  `print(res.mca)`



|   | Name   |             Description                                          |
|:-:|:------------------------|:----------------------------------------------------|
|1  |   "$eig"                |"eigenvalues"                                        |
|2  |   "$var"                |"results for the variables"                          |
|3  |   "$var$coord"          |"coord. of the categories"                           |
|4  |   "$var$cos2"           |"cos2 for the categories"                           |
|5  |   "$var$contrib"        |"contributions of the categories"                    |
|6  |   "$var$v.test"         |"v-test for the categories"                          |
|7  |   "$ind"                |"results for the individuals"                        |
|8  |   "$ind$coord"          |"coord. for the individuals"                         |
|9  |   "$ind$cos2"          |"cos2 for the individuals"                          |
|10 |   "$ind$contrib"        |"contributions of the individuals"                   |
|11 |  "$quali.sup"          |"results for the supplementary categorical variables"|
|12 |  "$quali.sup$coord"    |"coord. for the supplementary categories"            |
|13 |  "$quali.sup$cos2"     |"cos2 for the supplementary categories"              |
|14 |  "$quali.sup$v.test"   |"v-test for the supplementary categories"            |
|15 |  "$call"               |"intermediate results"                               |
|16 |  "$call$marge.col"     |"weights of columns"                                 |
|17 |  "$call$marge.li"      |"weights of rows"                                    |


### Comment on output of  `print(res.mca)`

`r fontawesome::fa("exclamation-triangle")`  `res.mca$svd` is not part of the output

- `eig` is computed from the singular values in `res.mca$svd`

- `var` contains material for plotting information about _categories_ and _variables_ on factorial planes

- `ind` contains material for plotting information about _individuals_ on on factorial planes


### `r fontawesome::fa("brain")`

Understanding MCA, the way it works, the ways it can be used amounts to understand the steps
that lead to the computation of `res.mca$svd`

Asserting that, by default, MCA consists of performing Correspondance Analysis (CA)  on the indicator matrix
deserves some explanation

In order to make the argument self-contained, we first skech what CA is and how it relates to (extensions of) SVD

Then, we explain what it means to perform CA on the indicator matrix

Finally we relate `res.mca$svd` with the extended SVD of the residual matrix of the indicator matrix


## Brush up your CA


---

### CA executive summary

- Start from a 2-way contingency table $X$ with $\sum_{i,j} X_{i,j}=N$
- Normalize $P = \frac{1}{N}X$ (_correspondance matrix_)
- Let $r$ (resp. $c$) be the row (resp. column) wise sums vector
- Let $D_r=\text{diag}(r)$ denote the diagonal matrix with row sums of $P$ as coefficients
- Let $D_c=\text{diag}(c)$ denote the diagonal matrix with column sums of $P$ as coefficients


+ The _row profiles matrix_ is $D_r^{-1} \times P$
+ The _standardized residuals matrix_ is  $S = D_r^{-1/2} \times \left(P - r c^T\right) \times D_c^{-1/2}$

CA consists in computing the SVD of the standardized residuals matrix $S =  U  \times D \times V^T$

From the SVD, we get
- $D_r^{-1/2} \times U$ standardized coordinates of rows
- $D_c^{-1/2} \times V$ standardized coordinates of columns
- $D_r^{-1/2} \times U \times D$ principal coordinates of rows
- $D_c^{-1/2} \times V \times D$ principal coordinates of columns
- Squared singular values: the principal inertia


When calling `svd(.)`, the argument should be
$$D_r^{1/2}\times \left(D_r^{-1} \times P \times D_c^{-1}- \mathbf{I}\times \mathbf{I}^T  \right)\times D_c^{1/2}$$


---

### CA and extended SVD

As
$$D_r^{-1} \times P \times D_c^{-1} - \mathbf{I}\mathbf{I}^T = (D_r^{-1/2} \times U)\times D \times (D_c^{-1/2}\times V)^T$$

$(D_r^{-1/2} \times U)\times D \times (D_c^{-1/2}\times V)^T$ is the _extended SVD_ of
$$D_r^{-1} \times P \times D_c^{-1} - \mathbf{I}\mathbf{I}^T$$
with respect to $D_r$ and $D_c$


## Performing CA on indicator matrix

### MCA: CA on indicator matrix

Let $X$ be the data matrix with $n$ rows (individuals) and $p$ categorical columns (variables)

For $j \in \{1, \ldots, p\}$, let $J_j$ denote the number of levels(categories) of variable $j$

Let $q = \sum_{j\leq p} J_j$ be the sum of the number of levels throughout the variables

Let $Z$ be the incidence matrix with $n$ rows and $q$ columns

For $j\leq p$ and $k \leq J_j$, let $\langle j, k\rangle = \sum_{j'<j} J_{j'}+k$

Let $N = n \times p = \sum_{i\leq n} \sum_{j \leq p} X_{i,j}$ and $P = \frac{1}{N} Z$ (the _correspondence matrix_ for MCA)

`r fontawesome::fa("hand-point-right")` The row wise  sums of correspondence matrix $P$ are all equal to $1/n=p/N$

The column wise sum of the correspondence matrix $P$ for the $k$th level of the $j$th variable of $X$ ( $j \leq p$ ) is $N_{\langle j,k\rangle}/N = f_{\langle j,k\rangle}/p$ where $f_{\langle j,k\rangle}$ stands for the relative frequency of level $k$ of the $j$th variable

$$D_r = \frac{1}{n}\text{Id}_n\qquad D_c =\text{diag}\left(\frac{f_{\langle j,k\rangle}}{p}\right)_{j \leq p, k\leq J_j}$$



### MCA: CA on incidence matrix (continued)

Let $r= D_r \times \mathbb{I}_n = \frac{1}{n} \mathbb{I}_p$  and $c = D_c \times \mathbb{I}_q$

In MCA, we compute the SVD $U \times D \times V^T$ of the standardized residuals matrix:

$$S = D_r^{-1/2}\times \left(P - r\times c^T\right) \times D_c^{-1/2} = \sqrt{n}\left(P - r\times c^T\right) \times D_c^{-1/2}$$

Coefficient $i, \langle j, k\rangle$  of $S$ is
$$\frac{\mathbb{I}_{i, \langle j, k\rangle}- f_{\langle j,k\rangle}}{\sqrt{n f_{\langle j,k\rangle}/p}}$$


`r fontawesome::fa("hand-point-right")`



### `r fontawesome::fa("ship")` Hand-made MCA on Titanic data


```{r, results='hide'}
tol <- 1e-10
X <- select(tit, Pclass, Sex, Embarked, Age) %>% drop_na()

p <- ncol(X)
Z <- tab.disjonctif(X)  #<< indicator matrix

n <- nrow(Z)
N <- sum(Z)
assert_that(N == n * p)
P <- Z/N   #<< correspondence matrix

r <- rowSums(P)
Dr <- diag(r)
assert_that(all(r == 1/n)) #<< sanity check
c <- colSums(P)
Dc <- diag(c)
S <- (P - r %o% c)  #<< residuals

# norm(S, "F")^2
assert_that(abs(sum(S)) <= 2 * tol)
SS <- diag(sqrt(r^(-1))) %*% S %*% diag(sqrt(c^(-1)))  #<< standardized residuals
# norm(SS, "F")^2

svd.SS <- svd(SS)  #<< bare MCA
assert_that(abs(sum(svd.SS$d^2) - norm(SS, "F")^2) < tol) #<< sanity check
```

### `r fontawesome::fa("ship")` Hand-made MCA on Titanic data (continued)

We may now compare `svd.SS`,  the SVD of the standardized residuals `SS`
with member `res.mca$svd` of `res.mca <- MCA(X)`

```{r, echo=FALSE}
res.mca <- FactoMineR::MCA(X, ncp=8, graph = FALSE)
```

The singular values coincide `r fontawesome::fa("glass-cheers")`

```{r, results='hide'}
assert_that(all(abs(res.mca$svd$vs - svd.SS$d)  <= 10 * tol))
```

Matrix `res.mca$svd$U`  is orthogonal with respect to $D_r$:

Matrix `res.mca$svd$U` equals $D_r^{-1/2} \times U$ (up to sign changes and numerical errors)

```{r, results='hide', eval=FALSE, echo=FALSE}
# assert_that(norm(abs(t(svd.SS$u[,1:8]) %*% diag(sqrt(r)) %*%  res.mca$svd$U) - diag(1, 7), "F") <= tol)
assert_that(norm(abs(t(res.mca$svd$U) %*%  res.mca$svd$U)/n - diag(1, 7), "F") <= tol)
```

Matrix `res.mca$svd$V`  is orthogonal with respect to $D_c$:

```{r, results='hide', eval=FALSE, echo=FALSE}
# assert_that(norm((t(res.mca$svd$V) %*% Dc[1:7, 1:7] %*% res.mca$svd$V) - diag(1, 7), "F") <= tol)
```

Matrix `res.mca$svd$V` equals $D_c^{-1/2} \times V$ (up to sign changes and numerical errors)

```{r, results='hide', eval=FALSE, echo=FALSE}
# assert_that(norm(abs(t(svd.SS$v[, 1:8]) %*% diag(sqrt(c)) %*% res.mca$svd$V) - diag(1, 8), "F") <= 1e-10)
```

`r fontawesome::fa("bullhorn")` `MCA(X)$svd` contains the _extended SVD_ of $D_r^{-1} \times P \times D_c^{-1} - \mathbf{I}\mathbf{I}^T$

## Zooming on other components of `res.mca`

### Component `res.mca$eig`


```{r}
eigv <- res.mca$svd$vs^2

tibble(eigenvalue=eigv,
       `% variance`=eigv/sum(eigv),
       `cum. % variance`= cumsum(eigv)/sum(eigv)) %>%
  rownames_to_column(var="Dimension") %>%
  head() %>%
  knitr::kable(digits=2)
```


The table on the left contains the first rows of `res.mca$eig`

Thanks to the Eckhart-Young Theorem  for extended SVD, component `$eig`
tells us how well the  matrix
$$D_r^{-1} \times(P -r \times c^T) \times D_c^{-1}$$
can be approximated by low
rank matrices according to the Hilbert-Schmidt norm with respect to $D_r$ and $D_c$



### Component `res.mca$var`


```{r, eval=FALSE}
coord <-  res.mca$var$coord
contrib <- res.mca$var$contrib
cos2 <- res.mca$var$cos2

assert_that(norm(res.mca$svd$V %*% diag(res.mca$svd$vs[1:8])
                 - coord, "F") <= tol)

tmp <- t(t(coord^2) %*% Dc) %*% diag(1/res.mca$svd$vs[1:8]^2)
assert_that(norm(100 * tmp - contrib, "F") <= tol)

assert_that(norm(cos2 - coord^2/rowSums(coord^2), "F") <= tol)
```

`res.mca$var` is a list of 3 matrices with the same dimensions $q$ (sum of level numbers)  and $q-p$

`$coord` is made of the principal coordinates of columns $D_c^{-1/2} \times V \times D$. Each row corresponds to one column of the indicator matrix

`$contrib` ...

`$cos2`  is derived from `$coord`. For each row (column of the indicator matrix) $\langle j, k\rangle$, for each
dimension $i$, the  $\langle j, k\rangle, i$ coefficient of `$cos2` is the squared cosine
of the angle between the row of $\langle j, k\rangle$ row of `$coord`  and the $i$th right singular vector

### Component `res.mca$ind`

.fl.w-50.pa2.f6[


```{r, eval=FALSE}
coord <-  res.mca$ind$coord
contrib <- res.mca$ind$contrib
cos2 <- res.mca$ind$cos2

assert_that(norm(res.mca$svd$U %*% diag(res.mca$svd$vs[1:8])
                 - coord, "F") <= tol)

tmp <- 100 * t(t(coord^2) %*% Dr) %*% diag(1/res.mca$svd$vs[1:8]^2)
assert_that(norm(tmp - contrib, "F") <= tol)

assert_that(norm(cos2 - coord^2/rowSums(coord^2), "F") <= tol)

```


`res.mca$ind` is a list of 3 matrices with the same dimensions $n$ (sum of level numbers)  and $q-p$

`$coord` is made of the principal coordinates of columns: $D_r^{-1/2} \times U \times D$. Each row corresponds to one row of the indicator matrix

`$contrib` ...

`$cos2`  is derived from `$coord`. For each row (row of the indicator matrix) $j$, for each
dimension $i$, the  $j, i$ coefficient of `$cos2` is the squared cosine
of the angle between the $j$th row of `$coord`  and the $i$th left singular vector



### More about MCA  (from `FactoMineR`)

`FactoMineR::MCA` does much more than computing an  SVD on a standardized residuals matrix

In real life MCA is performed on a subset of categorical columns of some data frame (the so-called
_active_ columns). The result
may help understanding the interplay between the active variables and the other variables

> MCA performs Multiple Correspondence Analysis (MCA) with supplementary individuals, supplementary quantitative variables and supplementary categorical variables.

> Performs also Specific Multiple Correspondence Analysis with supplementary categories and supplementary categorical variables.

> Missing values are treated as an additional level, categories which are rare can be ventilated ...

.fr.f6[From FactomineR documentation]


### Result of `MCA`


Beyond `$var`, `$ind`, `$eig`, `res.mca` contains further elements, including:

- `ind.sup`
a list of matrices containing all the results for the supplementary individuals (coordinates, square cosine)

- `quanti.sup`
a matrix containing the coordinates of the supplementary quantitative variables (the correlation between a variable and an axis is equal to the variable coordinate on the axis)

- `quali.sup`
a list of matrices with all the results for the supplementary categorical variables (coordinates of each categories of each variables, square cosine and v.test which is a criterion with a Normal distribution, square correlation ratio)

- `call`
a list with some statistics


### `r fontawesome::fa("binoculars")`

In a [tidy universe](http::tidyverse.org), there would exist  `tidy`, `augment` and `glance` methods for class `MCA` just as there are such methods for class `prcomp` (used to perform PCA)

Many components of `res.mca` could be computed by methods like `tidy`, `augment` and `glance` and
`MCA` would just return the extended SVD, matrices $D_r$, $D_c$ and some information from the call, like
the names of the active variables, the levels of each active variables, a vector recording the active individuals


## Visualization


### Inspecting Titanic using `factoextra`: screeplot

```{r}
knitr::kable(get_eigenvalue(res.mca), digits=2)
```


```{r}
fviz_screeplot(res.mca, addlabels=TRUE)
```

compare with `broom::tidy()` etc  for objects of class  `pca`


### `r fontawesome::fa("ship")` Plotting colums from data matrix


```{r tita_var, fig.show='hold', width=8}
fviz_mca_var(res.mca,
             choice = "var", ) +
  coord_fixed() +
  ggtitle("MCA Titanic, variables")
```


![](`r knitr::fig_chunk("tita_var", "png")`)



### Hand-made plots

The `plot` method for class `MCA` and the functions in `factoextra` provide off-the-shelf
constructions for classical MCA plots

There is nothing special about MCA plots

- the screeplot is a column plot
- the other plots are (sometimes decorated) scatter plots after some coordinate change

In the sequel, we build plots for categories, individuals and biplots using
the constructs from `ggplot2`


### `r fontawesome::fa("ship")` Plotting individuals on first factorial plane



```{r  tita_ind, fig.show='hold'}
res.mca.2 <- tit %>%
  select(Sex, Age, Embarked, Pclass, Survived) %>%
  MCA(quali.sup = c(5), graph = FALSE)

df_ind <- res.mca.2$ind$coord %>%
  as.data.frame() %>%
  bind_cols(Survived =tit$Survived) %>%
  drop_na()

df_ind %>%
  ggplot() +
  aes(x=`Dim 1`,
      y=`Dim 2`,
      colour=Survived) +
  geom_jitter(alpha=.2,
              width=.1,
              height = .1) +
  scale_color_viridis_d() +
  coord_fixed() +
  ggtitle("Titanic: indivudals in principal coordinates ")
```



![](`r knitr::fig_chunk("tita_ind", "png")`)




### `r fontawesome::fa("ship")` Plotting categories on first factorial plane



```{r  tita_cat, fig.show='hold'}
df_cat <- res.mca.2$var$coord %>%
  as.data.frame() %>%
  rownames_to_column(var="Category")

p <- df_cat %>%
  ggplot() +
  aes(x=`Dim 1`,
      y=`Dim 2`) +
  geom_point() +
  geom_text_repel(aes(label=Category)) +
  coord_fixed()

p +  ggtitle("Titanic: categories in principal coordinates ")
```




![](`r knitr::fig_chunk("tita_cat", "png")`)



### `r fontawesome::fa("ship")` MCA biplot


```{r  tita_biplot, fig.show='hold'}
p +
  geom_jitter(data=df_ind,
              aes(x=`Dim 1`,
                  y=`Dim 2`,
                  colour=Survived),
              alpha=.2,
              width=.1,
              height = .1
              ) +
  scale_color_viridis_d() +
  ggtitle("Titanic: biplot")
```

![](`r knitr::fig_chunk("tita_biplot", "png")`)

