---
title: "EDA I.3: Introduction to R and Data Analysis"
subtitle: "Analyse de Données Master I, MFA et MIDS"
author: "Stéphane Boucheron"
institute: "Université de Paris"
date: "2021/12/21 (updated: `r Sys.Date()`)"
params:
  title: "Introduction to table manipulations"
  curriculum: "Master I MIDS & MFA"
  coursetitle: "Analyse Exploratoire de Données"
  lecturer: "Stéphane Boucheron"
  homepage: "http://stephane-v-boucheron.fr/courses/eda/"
  curriculum_homepage: "https://master.math.univ-paris-diderot.fr/annee/m1-mi/"
  institution: "Université de Paris"
output:
  xaringan::moon_reader:
    css: ["header-footer.css", "xaringan-themer.css"]
    lib_dir: libs
    seal: false
    includes:
      in_header:
        - 'toc.html'
    nature:
      nature:
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);">
          </div>
        </div>
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
bibliography: mon_chapeau.bib
---
name: inter-slide
class: left, middle, inverse

{{ content }}

---
name: layout-general
layout: true
class: left, middle

```{r setup, child="loaders_fixers.Rmd", echo=FALSE, message=FALSE, warning=FALSE}

```


---


```{r child='title_slide.Rmd'}

```


---
template: inter-slide

## `r fontawesome::fa("map", fill="white")`

### [Tables](#dt)

### [SQL and Relational algebra with `dplyr`](#sql)

### [Tidy tables](#tidytables)

### [Aggregations](#aggregation)

### [Pivoting](#pivots)

### [Pipe](#pipe)

---
template: inter-slide
name: dt

## Tables


---

### Tables

- Speadsheets (Excel)

- `r fontawesome::fa("database")` Relational tables

- Dataframes in datascience frameworks

  - `r fontawesome::fa("r-project")`: `data.frame`, `tibble`, ...
  - `r fontawesome::fa("python")`: `pandas.dataframe`
  - `spark`: `dataframe`
  - `Dask`: `dataframe`
  - and many others

???

In Data Science, each framework comes with its own flavor(s) of table

Tables from relational databases serve as inspiration

In `r fontawesome::fa("r-project")` legacy dataframes shape the life of statisticians and data scientists

The purpose of this session is

- describing dataframes from an end-user viewpoint (we leave aside implemenations)
- learning tools for
  - accessing information within dataframes (querying)
  - summarizing information
  - cleaning dataframes
  - tidying dataframes

---

### Loading tables and packages


```{r}
pacman::p_load("tidyverse")      # All we need is there
# Almost all. Helper packages
pacman::p_load("nycflights13")    # for flight data
pacman::p_load("lubridate")
pacman::p_load("DT")
pacman::p_load("gt")
pacman::p_load("kableExtra")
data(flights)
```

???

[`tidyverse`]() provides tools to create, query, tidy dataframes as well as tools
to load data from various sources and save them in persistent storage

[`nycflights13`]() provides the dataframes we paly with

[`DT`]() is a gateway to a Javascript library that enables gracious display of dataframes
on the www



---

### The `flights` table

```{r}
head(flights, 10)  #<<
# head(flights)
```

???

A dataframe is a two-ways table

`head(df)` displays the first 6 rows of its first argument

The cells of a dataframe may have different types/classes


---


### Table schema

.fl.w-30.pa2.f6[

A table is a _list_ of _columns_

Each _column_ has

- _name_ and
- _type_ (_class_ in `r fontawesome::fa("r-project")`)


```{r glimpse-schema, eval=FALSE}
glimpse(flights,   #<<
        width=50)
```
]


.fl.w-70.pa2.f6[

```{r glimpse-schema-out, echo=FALSE, ref.label="glimpse-schema"}

```

]




???

- `flights` has `r length(flights)` columns
- Each column is  a sequence (`vector`) of items with the same type/class
- All columns have the same length
- `flights` has `r nrow(flights)` rows
- In `r fontawesome::fa("database")` parlance a row is (often) called a _tuple_
- In `r fontawesome::fa("database")` parlance a column is (often) called a _variable_

---

### Column types

.fl.w-50.pa2[

| class |  columns |
|:-----:|:---------|
| `integer`   |  'year' 'month' 'day' 'dep_time' 'sched_dep_time' 'arr_time' 'sched_arr_time' 'flight'  |
| `numeric`  | 'dep_delay' 'arr_delay' 'air_time' 'distance' 'hour' 'minute'  |
| `character`   |  'carrier' 'tailnum' 'origin' 'dest' |
| `POSIXct`   |  'time_hour' |
| `POSIXt`   |  'time_hour' |


]

.fl.w-50.pa2[

A column, as a vector, may be belong to different classes

Other classes:  `factor` for categorical variables

Columns `dest`, `origin` `carrier` could be coerced as factors

Should columns `dest`  and `origin` be coerced to the same factor?

]


---

### Columns specification

.fl.w-30.pa2[
```{r, eval=FALSE}
as.col_spec(flights)
```
]

.fl.w-70.pa2.f6[
```{r, eval=FALSE}
cols(
  year = col_integer(),
  month = col_integer(),
  day = col_integer(),
  dep_time = col_integer(),
  sched_dep_time = col_integer(),
  dep_delay = col_double(),
  arr_time = col_integer(),
  sched_arr_time = col_integer(),
  arr_delay = col_double(),
  carrier = col_character(),
  flight = col_integer(),
  tailnum = col_character(),
  origin = col_character(),
  dest = col_character(),
  air_time = col_double(),
  distance = col_double(),
  hour = col_double(),
  minute = col_double(),
  time_hour = col_datetime(format = "")
)
```
]


???

Table schema in relational databases

Column specifications are useful when loading dataframes from structured text files
like `.csv` files

`.csv` files do not contain typing information

File loaders from package `readr` can be tipped about column classes using column specifications

---
template: inter-slide
name: sql

## SQL and Relational algebra with `dplyr`

???


SQL stands for structured/simple query language

A query language elaborated during the 1970's at IBM by Codd

Geared towards exploitation of collections of relational tables

Less powerful but simpler to use than a programming language

`dplyr` is a principled `r fontawesome::fa("r-project")`-friendly
implementation of SQL ideas (and other things)

At the core of SQL lies the idea of a table calculus called relational algebra

---

### Relational algebra (basics)

Convention: $R$  is a table with columns $A_1, \ldots, A_k$


- Projection (picking columns)

.f3[

$\pi(R, A_1, A_3)$

]

- Selection/Filtering (picking rows)

.f3[

$\sigma(R, {\text{condition}})$

]

- Join (mulitple tables operation)

.f3[

$\bowtie(R,S, {\text{condition}})$

]

`r fontawesome::fa("hand-point-right")` Any operation produces a table.

`r fontawesome::fa("hand-point-right")` The schema of the derived table depends on the operation (but does not depend on the content/value of the operands)


???

Relational calculus relies on a small set of basic operations $\pi, \sigma, \bowtie$

Each operation has one or two table operands and produce a table

There is more to SQL than relational algebra

---

.f3[

$\pi(R, {A_1, A_3})$

]

A projection  $\pi(\cdot, {A_1, A_3})$ is defined by a set of column names, say $A_1, A_3$

If $R$ has columns with given names, the result is a table with names $A_1, A_3$ and one row per row of $R$

A projection is parametrized by a list of column names

???

- Checks

- Variable number of arguments or list argument

- What if $R$ does not have columns named $A_1, A_3$?

---

### `r fontawesome::fa("tools")` Package `dplyr`

.fl.w-30.pa2[

- [_Tranformation_ chapter in R4DS](https://r4ds.had.co.nz/transform.html)

- [Cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf)

]

.fl.w-70.pa2[

```{r, echo=FALSE}
knitr::include_url("https://dplyr.tidyverse.org")
```

[https://dplyr.tidyverse.org](https://dplyr.tidyverse.org)

]


???

Base `r fontawesome::fa("r-project")` provides tools to perform relational algebra
operations

But:

- Base `r fontawesome::fa("r-project")` does  not provide a consistent API

- The lack of a consistent API makes operation chaining tricky

---

### `dplyr` verbs

Five basic verbs:

- Pick observations/rows by their values (`filter()`)  .fr[ σ(...) ]

- Pick variables by their names (`select()`)    .fr[ π(...)]

- Reorder the rows (`arrange()`)

- Create new variables with functions of existing variables (`mutate()`)

- Collapse many values down to a single summary (`summarise()`)

--

And

- `group_by()`  changes the scope of each function from operating on the entire dataset to operating on it group-by-group.

???


---

### `r fontawesome::fa("umbrella-beach")` tidyverse

.fl.w-50.pa2[

> All verbs work similarly:

> The first argument is a data frame (table).

> The subsequent arguments describe what to do with the data frame, using the variable/column names (without quotes)

> The result is a new data frame (table).

]

.fl.w-50.pa2[

```{r, echo=FALSE}
knitr::include_url("https://www.tidyverse.org")
```
]


???

`dplyr` is part of `tidyverse`

`dplyr` provides a consistent API


---

### `dplyr::select()` as a projection operator (π)

$\pi(R, \underbrace{A_1, \ldots, A_3}_{\text{column names}})$

```{r, eval=FALSE}
select(R, A1, A3) #<<
```

or,  equivalently

```{r, eval=FALSE}
R %>% select(A1, A3) #<<
```

`r fontawesome::fa("hand-point-right")` `%>%` is the pipe operator from `magrittr`

`r fontawesome::fa("hat-wizard")` `x %>% f(y, z)` is translated to `f(x, y, z)` and then evaluated

???

Function `select` has a variable number of arguments

Function `select`  has a variable number of arguments

Function `select` allows to pick column by names (and much more)

Note that in the current environment, there are no objects called `A1`, `A3`

The conistent API allows to use the pipe operator

---

### Toy tables

.fl.w-50.pa2[

```{r toy-tables, message=FALSE, warning=FALSE}
spam <- set.seed(42)

R <-  tibble(A1=seq(2, 10, 2),
             A2=sample(letters, 5),
             A3=seq(from=date("2021-10-21"),
                    to=date("2021-11-20"),
                    by=7),
             D=sample(letters, 5))

S <- tibble(E=c(3,4,6,9, 10),
            F=sample(letters, 5),
            G=seq(from=date("2021-10-21"),
                   to=date("2021-10-21")+4, by=1),
            D=sample(letters,5)
          )
```
]

.fl.w-50.pa2[

```{r, echo=FALSE}
knitr::kable(R, caption="R")
knitr::kable(S, caption="S")
```


]


???




---

### Projecting `flights` on `origin`  and `dest`

.fl.w-50.pa2[

```{r flights-select, eval=FALSE}
flights %>%
  select(origin, dest) %>%  #<<
  head()
```

A more readable equivalent of

```{r, eval=FALSE}
head(select(flights,
            origin,
            dest),
     10)
```
]

.fl.w-50.pa2[

```{r flights-select-out, echo=FALSE, ref.label="flights-select"}

```

```{psql, eval=FALSE, echo=TRUE}
SELECT origin, dest
FROM flights
LIMIT 10;
```


]


???




---

.f3[

$\sigma(R, \text{condition})$

]

A selection/filtering operation is defined by a condition that can be checked on the rows of tables with convenient schema

$\sigma(R, \text{condition})$ returns a table with the same schema as $R$

The resulting table contains the rows/tuples of $R$ that satisfy $\text{condition}$

$\sigma(R, \text{FALSE})$ returns an empty table with the same schema as $R$


---



### Chaining filtering and projecting

.fl.w-50.pa2[

```{r toy-filter-project, eval=FALSE}
start <- date("2021-10-27")
end <- start + 21

R %>%
  filter(A2 > "n" , #<<
         between(A3, start, end)) %>%
  select(A1, A3) #<<
```

]

.fl.w-50.pa2[

```{r toy-filter-project-out, echo=FALSE, ref.label="toy-filter-project"}

```

]
---

### Selecting `flights` based on `origin`  and `dest`

and then projecting on `dest, time_hour, carrier`

.fl.w-50.pa2[

```{r flights-filter-select, eval=FALSE}
flights %>%
  filter(dest %in% c('ATL', 'LAX'), #<<
         origin == 'JFK') %>%
  select(dest, time_hour, carrier) %>% #<<
  head()
```

- In SQL (`r fontawesome::fa("database")`) parlance:

```{psql, eval=FALSE,}
SELECT dest, time_hour, carrier
FROM flights
WHERE dest IN ('ATL', 'LAX') AND
      origin = 'JFK'
LIMIT 6
```
]

.fl.w-50.pa2[

```{r flights-filter-select-out, echo=FALSE, ref.label="flights-filter-select"}

```

]
???

Filtering is also called subsetting




---

### Logical operations

`filter(R, condition_1, condition_2)` is meant to return the rows of `R` that satisfy `condition_1` **and** `condition_2`

`filter(R, condition_1 & condition_2)` is an equivalent formulation

`filter(R, condition_1 | condition_2)` is meant to return the rows of `R` that satisfy `condition_1` **or** `condition_2` (possibly both)

`filter(R, xor(condition_1,condition_2))` is meant to return the rows of `R` that satisfy **either** `condition_1` **or** `condition_2` (just one of them)

`filter(R, ! condition_1)` is meant to return the rows of `R` that **do not** satisfy  `condition_1`

---

### Overview of set and boolean operations


![](./img/transform-logical.png)

---

### `r fontawesome::fa("skull-crossbones")` Missing values!

Numerical column `dep_time` contains many `NA's` (missing values)

```{r}
summary(flights$dep_time)
```

`r fontawesome::fa("hand-point-right")` Missing values (`NA` and variants) should
be handled with care

```{r, results='asis'}
NA & TRUE
NA | TRUE
```

---

### Truth tables for three-valued logic

.fl.w-50.pa2[

`r fontawesome::fa("exclamation-triangle")` `r fontawesome::fa("r-project")` uses _three-valued logic_

`r fontawesome::fa("hand-point-right")` Generate complete truth tables for `and, or, xor`

```{r, echo=TRUE}
v <- c(TRUE, FALSE, NA) # truth values

list_tt <- map(c(`&`, `|`, xor),  #<<
               ~ outer(v, v, .x)) #<<

for (i in seq_along(list_tt)){
  colnames(list_tt[[i]]) <- v
  rownames(list_tt[[i]]) <- v
}

names(list_tt) <- c('& AND',
                    '| OR',
                    'XOR')
```
]

--

.fl.w-50.pa2.f6.tl[

```{r, echo=FALSE, results='asis'}

for (i in 1:3){
print(
  kbl(list_tt[[i]], caption=names(list_tt[i])) %>%
  kable_minimal(position = "left", full_width= FALSE) %>%
  column_spec(1, bold = T, background = "lightgray") %>%
  row_spec(0, bold = T, background = "lightgray")
)
  cat('<br>\n\n<!-- -->\n\n')
}

```

]

---
exclude: true

|  <div style="width:80px">`and`</div> | <div style="width:80px">`TRUE`</div>  | <div style="width:80px">`FALSE`</div> |<div style="width:80px">`NA`</div>    |
|:-----|:-----|:-----|:-----|
|**`TRUE`**  |TRUE  |FALSE |NA    |
|**`FALSE`** |FALSE |FALSE |FALSE |
|**`NA`**    |NA    |FALSE |NA    |

<br>

|  <div style="width:80px">`or`</div> | <div style="width:80px">`TRUE`</div>  | <div style="width:80px">`FALSE`</div> |<div style="width:80px">`NA`</div>    |
|:-----|:----|:-----|:----|
|**`TRUE`**  |TRUE |TRUE  |TRUE |
|**`FALSE`** |TRUE |FALSE |NA   |
|**`NA`**    |TRUE |NA    |NA   |

<br>

|  <div style="width:80px">`xor`</div> | <div style="width:80px">`TRUE`</div>  | <div style="width:80px">`FALSE`</div> |<div style="width:80px">`NA`</div>    |
|:-----|:-----|:-----|:--|
|**`TRUE`** |FALSE |TRUE  |NA |
|**`FALSE`** |TRUE  |FALSE |NA |
|**`NA`**   |NA    |NA    |NA |



---

### `slice()`: choosing rows based on location

.fl.w-50.pa2[

In base `r fontawesome::fa("r-project")` dataframe cells can be addressed by
indices

`flights[5000:5010,seq(1, 19, by=5)]` returns rows `5000:5010` and columns
`1, 6, 11` from dataframe `flights`

This can be done in a (verbose) `dplyr` way using `slice()` and `select()`

]

.fl.w-50.pa2[
```{r}

flights %>%
  slice(5001:5005) %>%  #<<
  select(seq(1, 19, by=5))
```
]

???

Useful variant `slice_sample()`

---
template: inter-slide


## Joins : multi-table queries



---

.f3[

$\bowtie(R,S, {\text{condition}})$

]

stands for

> join rows/tuples of $R$ and rows/tuples of $S$  that satisfy $\text{condition}$


---

### `nycflights` tables

The `nycflights13` package  offers five related tables:

- _Fact_ tables:
  - `flights`
  - `weather`  (hourly weather conditions at different locations)

- _Dimension_ tables:
  - `airports`  (airports full names, location, ...)
  - `planes`    (model, manufacturer, year, ...)
  - `airlines`  (full names)

This is an instance of a [Star Schema](https://en.wikipedia.org/wiki/Star_schema)

???

---

### Star schema

> Fact tables record measurements for a specific event

> Fact tables generally consist of numeric values, and foreign keys to dimensional data where descriptive information is kept

.fr[From [Wikipedia](https://en.wikipedia.org/wiki/Star_schema)]

---

### Star schema illustrated

![](./img/relational-nycflights.png)

---

### `r fontawesome::fa("wind")` weather conditions

.f6[

```{r}
weather %>%
  glimpse(width = 50)
```

]

---

### Connecting `flights`  and `weather`


We want to complement information in `flights` using data `weather`

Motivation: we would like to relate delays (`arr_delay`) and weather conditions

- can we explain (justify) delays using weather data?

- can we predict delays using weather data?

---

### `r fontawesome::fa("plane-departure")` ⋈  `r fontawesome::fa("wind")`



For each flight (row in `flights`)

- `year`, `month`, `day`, `hour` (computed from `time_hour`) indicate
the approaximate time of departure

- `origin` indicates the airport where the plane takes off

Each row of `weather` contains corresponding information

`r fontawesome::fa("hand-point-right")` for each row of `flights` we look for rows of `weather`
with matching values in `year`, `month`, `day`, `hour`  and `origin`

`r fontawesome::fa("hand-point-right")` NATURAL INNER JOIN between the tables

---

### `inner_join`: natural join

.fl.w-30.pa2[

```{r flights-weather, eval=FALSE}
f_w <- flights %>%
  inner_join(weather) #<<

head(f_w)
```
]

.fl.w-70.pa2.f6[

```{r flights-weather-out, echo=FALSE, ref.label="flights-weather"}

```

]

???



---

### Join schema

.f6[

```{r, echo=FALSE}
f_w %>%
  glimpse(width=50)
```
]

???

The schema of the result is the union of the schemas of the operands

A tuple from `flights` matches a tuple from `weather` if the tuple have the same values in the common columns

`r names(f_w)`


---

### Which columns are used when joining tables $R$ and $S$?

- _default behavior_ of `inner_join`: all columns shared by  $R$ and $S$. Common columns  have the same name
in both schema. They are expected to have the same class

- _manual definition_: in many settings, we  want to overrule the default behavior. We specify
manually which column from $R$ should match which column from $S$

---

### Natural join of  `flights`  and `weather`:

```{r}
common_names <- base::intersect(names(weather),
                                names(flights))

setequal(
  inner_join(flights, weather),
  inner_join(flights,
             weather,
             by=common_names)
)
```

---

### `r fontawesome::fa("brain")` Are you surprised by the next chunk?

```{r}
dtu  <- inner_join(flights,
           weather,
           by=c("year", "month", "day", "origin", "hour"))

dtv <- inner_join(flights,
           weather,
           by=c("origin", "time_hour"))

setequal(dtu, dtv)
```

Recall that columns `year`, `month` `day` `hour` can be computed from  `time_hour`

```{r}
# helper for datetime objects
require(lubridate)

flights %>%
  filter(year!=year(time_hour) |
         month!=month(time_hour) |
         day!=day(time_hour) |
         hour!=hour(time_hour)) %>%
  nrow()
```

???

This is an example of functional dependency


---

The two results do not have the same schema!

```{r}
setdiff(colnames(dtv), colnames(dtu))
setdiff(colnames(dtu), colnames(dtv))
```

--

Fixing

```{r}
dtu  <- inner_join(flights,
           weather,
           by=c("year", "month", "day", "origin", "hour"),
           suffix= c("", ".y")) %>%  #<<
           select(-ends_with(".y"))  #<<

dtv <- inner_join(flights,
           weather,
           by=c("origin", "time_hour"),
           suffix= c("", ".y")) %>%  #<<
           select(-ends_with(".y"))  #<<

setequal(dtu, dtv)
```

---

### About `inner_join`

.fl.w-40.pa2[

```{r, eval=FALSE}
inner_join(
  x, y,
  by = NULL,      #<<
  copy = FALSE,
  suffix = c(".x", ".y"), #<<
  ...,
  keep = FALSE,  #<<
  na_matches = "na")  #<<
```

]

.fl.w-60.pa2[

- `by`:
  - `by=c("A1", "A3", "A7")` row `r` from `R` and `s` from `S` match if `r.A1 == s.A1`,
  `r.A3 == s.A3`,   `r.A7 == s.A7`
  - `by=c("A1"="B", "A3"="C", "A7"="D")` row `r` from `R` and `s` from `S` match if `r.A1 == s.B`,
  `r.A3 == s.C`,   `r.A7 == s.D`

- `suffix`: If there are non-joined duplicate variables in `x` and `y`, these suffixes will be added to the output to disambiguate them.

- `keep`: Should the join keys from _both_ `x` and `y` be preserved in the output?

- `na_matches`: Should NA and NaN values match one another?

.fl[From online documentation]

]

???


---

### Join flavors

Different flavors of `join` cab be used to join one table to columns from another, matching values with the rows that they correspond to

Each join retains a different combination of values from the tables

- `left_join(x, y, by = NULL, suffix = c(".x", ".y"), ...)` Join matching values from `y` to `x`.
Retain all rows of `x` padding missing values from `y` by `NA`

- `semi_join` ...

- `anti_join` ...


???

---

### Toy examples : `inner_join`

.fl.w-30.pa2.f6[


```{r zetoytables, echo=FALSE}
R %>% kable(caption="R")
S %>% kable(caption="S")
```
]

.fl.w-70.pa2.f6[

```{r, echo=FALSE}
kable <- knitr::kable
inner_join(S, R, by=c("E"="A1")) %>% kable(caption='inner_join(S, R, by=c("E"="A1"))')

```

]

---

### Toy examples : `left_join`

.fl.w-30.pa2.f6[

```{r zetoytables-out, echo=FALSE, ref.label="zetoytables"}
```

]

.fl.w-70.pa2.f6[

```{r, echo=FALSE}
left_join(S, R, by=c("E"="A1")) %>% kable(caption='left_join(S, R, by=c("E"="A1"))')
```
]

---

### Toy examples : `semi_join` `anti_join`

.fl.w-30.pa2.f6[

```{r zetoytables-out-2, echo=FALSE, ref.label="zetoytables"}
```

]

.fl.w-70.pa2.f6[

```{r, echo=FALSE}
semi_join(S, R, by=c("E"="A1")) %>% kable(caption='semi_join(S, R, by=c("E"="A1"))')
```

<br><br>

```{r, echo=FALSE}
anti_join(S, R, by=c("E"="A1")) %>% kable(caption='anti_join(S, R, by=c("E"="A1"))')
```

]

---
### Conditional/ $\theta$ -join

In relational databases, joins are not restricted to _natural joins_

--

$$U \leftarrow R \bowtie_{\theta} S$$

reads as

$$\begin{array}{rl}
T & \leftarrow R \times S\\
U & \leftarrow \sigma(T, \theta)\end{array}$$

where

- $R \times S$ is the _cartesian product_ of $R$ and $S$

- $\theta$ is a boolean expression that can be evaluated on any tuple of $R \times S$

---

### Do we need conditional/ $\theta$ -joins?

- `r fontawesome::fa("hand-point-right")`: We can implement $\theta$/conditional-joins by pipelining a cross product and a filtering

--

- `r fontawesome::fa("skull-crossbones")`: Cross products are costly:
  + $\#\text{rows}(R \times S) = \#\text{rows}(R) \times \#\text{rows}(S)$
  + $\#\text{cols}(R \times S) = \#\text{cols}(R) + \#\text{cols}(S)$

--

- `r fontawesome::fa("database")`: RDBMS use query planning and optimization, indexing to circumvent the cross product bottleneck (when possible)

--

- `r fontawesome::fa("r-project")`: if we need to perform a $\theta$-join
  + outsource it to a RDBMS, or
  + design an ad hoc pipeline



.fr[
[About conditional join](https://www.r-bloggers.com/2018/02/in-between-a-rock-and-a-conditional-join/)
]


---

### A conditional join between `flights` and `weather`

- The natural join between `flights` and `weather` we implemented can be regarded as an ad hoc conditional join between normalized versions of `weather` and `flights` `r fontawesome::fa("lightbulb")`


- Table `flights` and `weather` are redundant: `year`, `month`, `day`, `hour` can be computed from `time_hour`


- Assume `flights` and `weather` are trimmed so as to become irredundant



- The conditional join is then based on _truncations_ of variables `time_hour`

```{psql, eval=FALSE}
SELECT *
FROM flights AS f, weather AS w
WHERE date_trunc('hour', f.time_hour) = date_trunc('hour', w.time_hour)
```

- Adding redundant columns to `flights` and `weather` allows us to transform
a tricky conditional join into a simple natural join `r fontawesome::fa("glass-cheers")`


.fr[
[PostgreSQL documentation](https://www.postgresql.org/docs/14/index.html)
]


---
template: inter-slide
name: beyonddplyr

## Creating new columns

---

Creation of new columns may happen

- on the fly

- when altering (enriching) the schema of a table

In databases, creation of new columns may be the result of a query or be the result of altering a table schema with `ALTER TABLE ADD COLUMN ...`

In `tidyverse()` we use verbs `mutate`  or `add_column` to add columns to the input table

---

### `mutate`

.fl.w-50.pa2[

```{r, eval=FALSE}
mutate(   #<<
  .data,
  new_col= expression, #<<
  ...,   #<<
  .keep = c("all", "used", "unused", "none"),
  .before = NULL,
  .after = NULL
)
```

]


.fl.w-50.pa2[

`.data`: the input data frame

`new_col= expression`:

-  `new_col` is the name of a new column

-  `expression` is evaluated on each row of `.data` or it is a vector of length `1`

- `all` is the default behavior, retains all columns from `.data`


]



---

### Creating a categorical column to spot large delays

.fl.w-50.pa2[

```{r mutatis, eval=FALSE}
breaks_delay <- with(flights,
  c(min(arr_delay, na.rm=TRUE),
    0, 30,
    max(arr_delay, na.rm=TRUE)))

level_delay <- c("None",
                 "Moderate",
                 "Large")

flights %>%
  mutate(large_delay = cut(arr_delay,  #<<
    breaks=breaks_delay, #<<
    labels=level_delay,  #<<
    ordered_result=TRUE)) %>%   #<<
  select(large_delay, arr_delay) %>%
  sample_n(5)
```

]


.fl.w-50.pa2[

```{r mutatis-out, echo=FALSE, ref.label="mutatis"}

```
]


???

```{r}
flights %>%
  mutate(foo = if_else(arr_time > sched_arr_time,        #<<
                              arr_time - sched_arr_time,
                              0L,
                              missing = NA_integer_)) %>%
  group_by( (foo >0) & abs(foo - arr_delay)  > 100) %>%
  summarise(N=n())

```


---

### Changing the class of a column


.fl.w-50.pa2[

```{r mutandis, eval=FALSE}
flights %>%
  mutate(large_delay = cut(arr_delay,  #<<
    breaks=breaks_delay,
    labels=level_delay,
    ordered_result=TRUE),
    origin = as.factor(origin), #<<
    dest = as.factor(dest)    #<<
  ) %>%
  select(large_delay,
    arr_delay,
    origin,
    dest) %>%
  sample_n(5)
```

]


.fl.w-50.pa2[

```{r mutandis-out, echo=FALSE, ref.label="mutandis"}

```
]

---
template: inter-slide
name: tidytables

## Tidy tables


---

Tidying tables is part of data cleaning

> A (tidy) dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative)

> Values are organised in two ways

> Every value belongs to a _variable_ and an _observation_

> A _variable_ contains all values that measure the same underlying attribute (like height, temperature, duration) across _units_

> An _observation_ contains all values measured on the same _unit_ (like a person, or a day, or a race) across attributes

> The principles of tidy data are tied to those of relational databases and Codd's relational algebra


.fr[[`r fontawesome::fa("book")` The tidy data paper](https://vita.had.co.nz/papers/tidy-data.html)]


---

### `r fontawesome::fa("bullhorn")`

`r fontawesome::fa("hand-point-right")` `dplyr` functions expect and return _tidy_ tables

In a _tidy_ table

- Each variable is a column

- Each observation is a row

- Every cell is a single value

.fr[[`r fontawesome::fa("book")` The tidy data paper](https://vita.had.co.nz/papers/tidy-data.html)]

???

`r fontawesome::fa("hand-point-right")` In order to tell whether a table is tidy, we need to know what is the _population_ under investigation,
what are the observations/individuals, which measures are performed on each individual, ...

---

### Untidy data

> Column headers are values, not variable names.

> Multiple variables are stored in one column.

> Variables are stored in both rows and columns.

> Multiple types of observational units are stored in the same table.

> A single observational unit is stored in multiple tables.

> ...


.fr[ `r fontawesome::fa("tools")` ]

???

Source of untidyness

---

### Functions from `tidyr::...`

- `pivot_wider` and `pivot_longer`

- `separate` and  `unite`

- Handling missing values with `complete`, `fill`, ...

- ...

[`tidyr` website](https://tidyr.tidyverse.org)


---

### Pivot longer

.fl.w-50.pa2[

> `pivot_longer()` is commonly needed to tidy wild-caught datasets as they often optimise for ease of data entry or ease of comparison rather than ease of analysis.


```{r, echo=FALSE}
messy <- tibble::tribble(
~row, ~a, ~b, ~c,
"A", 1, 4, 7,
"B", 2, 5, 8,
"C", 3, 6, 9,
)

messy %>% kable()
```

]

.fl.w-50.pa2[

```{r}
messy %>% pivot_longer(
  cols=c(-row),  #<<
  names_to = "name",
  values_to = "value",
)  %>% kable()
```

]

???


> `pivot_longer()` makes datasets longer by increasing the number of rows and decreasing the number of columns. I don’t believe it makes sense to describe a dataset as being in “long form”. Length is a relative term, and you can only say (e.g.) that dataset A is longer than dataset B.

---

### Pivot wider

.fl.w-50.pa2[

```{r, eval=FALSE}
pivot_wider(  #<<
  data,
  id_cols = NULL, #<<
  names_from = name, #<<
  names_prefix = "",
  values_from = value, #<<
  ...
)
```
`r fontawesome::fa("hand-point-right")` some optional arguments are missing

]

.fl.w-50.pa2[
When reporting, we often use `pivot_wider` (explicitely or implicitely)
to make results more readable, possibly to conform to a tradition

- Life tables in demography and actuarial science
- Longitudinal data
- See slide [How many flights per day of week per departure airport?](#aggregate-pivot-wider)
]

---


---
template: inter-slide
name: aggregation

## Aggregations

---

### How many flights per carrier?

.fl.w-50.pa2[

```{r flights_carrier, eval=FALSE}
flights %>%
  group_by(carrier) %>%  #<<
  summarise(count=n()) %>%  #<<
  arrange(desc(count))
```

```{psql, eval=FALSE}
SELECT carrier, COUNT(*) AS n
FROM flights
GROUP BY carrier
ORDER BY n DESCENDING
```
]

.fl.w-50.pa2[

```{r flights_carrier-out, ref.label="flights_carrier", echo=FALSE}

```

]

???

> `group_by`

> `summarise`

> `arrange`

---
name: aggregate-pivot-wider

### How many flights per day of week per departure airport?

.fl.w-40.pa2.f6[

```{r flights-dow, eval=FALSE}
flights %>%
  group_by(origin,  #<<
           wday(time_hour)) %>%  #<<
  summarise(count=n()) %>%       #<<
  rename(day_of_week=`wday(time_hour)`) %>%
  pivot_wider(  #<<
    id_cols="origin",
    names_from="day_of_week",
    names_prefix="day_",
    names_sep="_",
    values_from="count") %>%
  kable(caption="Departures per day")
```

]

.fl.w-60.pa2.f6[

```{r flights-dow-out, echo=FALSE, ref.label="flights-dow"}

```

]


---
name: pipe
class: middle, left, inverse
background-image: url('./img/pexels-andris-bergmanis-7891767.jpg')
background-size: cover

## Pipelines/chaining operations

---

### `%>%`, `|>` and other pipes

> All `dplyr` functions take a table as the first argument

> Rather than forcing the user to either save intermediate objects or nest functions, `dplyr` provides the `%>%` operator from `magrittr`

> `x %>% f(y)` turns into `f(x, y)`

> The result from one step is  _piped_ into the next step

> Use `%>%`  to rewrite multiple operations that you can read left-to-right/top-to-bottom

```{r, eval=FALSE}
g(f(x, y), z)

x %>%
  f(y) %>%
  g(z)
```

.fr[From [dplyr vignette](https://dplyr.tidyverse.org/articles/dplyr.html)]

---
exclude: true

### Unix pipe `|`


---

### Magrittr `%>%`

.fl.w-50.pa2[

`%>%` is not tied to `dplyr`

`%>%` can be used with packages from `tidyverse`

`%>%` can be used outside `tidyverse` that is with functions which take a table (or something else) as a second, third or keyword argument

`r fontawesome::fa("magic")` Use pronoun `.` to denote the LHS of the pipe expression

]


.fl.w-50.pa2[

Second argument of `g` has the same type as the result of `f`

```{r, eval=FALSE}
g(z, f(x, y))

x %>%
  f(y) %>%
  g(z, .)   #<<
```

`x %>% f(y)` is a shorthand for `x %>% f(., y)`
]


---

### Standard pipe `|>` (version > 4.)

As of version 4.1 (2021), base `r fontawesome::fa("r-project")` offers a pipe operator denoted by `|>`

.fl.w-50.pa2[

`x |> f(y)` turns into `f(x, y)`


```{r, eval=FALSE}
g(f(x, y), z)

x |>
  f(y) |>
  g(z)
```

]

.fl.w-50.pa2[

`r fontawesome::fa("hand-point-right")` the standard pipe `|>` has no pronoun/placeholder to denote the LHS of the pipe expression

The roundabout consists in using another new construct `\(x)`

```{r, eval=FALSE}
g(z, w)

x |>
  (\(x) g(z, w=x))()
```

```{r}
"une" |>
  (\(x) str_c("ceci n'est pas", x, sep=" "))() |>
  str_c("pipe", sep=" ") |>
  cat()
```
]

.fr[[Blog on the new standard pipe](https://www.r-bloggers.com/2021/05/the-new-r-pipe/)]

---

### Other pipes

`Magrittr` offers several variants of `%>%`

- Tee operator `%T>%`
- Assignement pipe `%<>%
- Exposition operator `%$%`
- ...  `

.fr[[pipes for beginners](https://www.r-bloggers.com/2017/12/pipes-in-r-tutorial-for-beginners/)]

---
template: inter-slide

## References


---

- [R for Data Science](https://r4ds.had.co.nz)
  + [Data transformation](https://r4ds.had.co.nz/transform.html)
- [Cheat sheets]

-

---
exclude: true

```{r}
family <- tibble::tribble(
  ~family,  ~dob_child1,  ~dob_child2, ~gender_child1, ~gender_child2,
       1L, "1998-11-26", "2000-01-29",             1L,             2L,
       2L, "1996-06-22",           NA,             2L,             NA,
       3L, "2002-07-11", "2004-04-05",             2L,             2L,
       4L, "2004-10-10", "2009-08-27",             1L,             1L,
       5L, "2000-12-05", "2005-02-28",             2L,             1L,
)

family %>%
  mutate(across(starts_with("dob"),  readr::parse_date)) %>%
  pivot_longer(
   !family,
   names_to = c(".value", "child"),
   names_pattern = "([a-z]*)_child(.)",
   values_drop_na = TRUE
 )

pivot_longer_spec
#> # A tibble: 5 × 5
#>   family dob_child1 dob_child2 gender_child1 gender_child2
#>    <int> <date>     <date>             <int>         <int>
#> 1      1 1998-11-26 2000-01-29             1             2
#> 2      2 1996-06-22 NA                     2            NA
#> 3      3 2002-07-11 2004-04-05             2             2
#> 4      4 2004-10-10 2009-08-27             1             1
#> 5      5 2000-12-05 2005-02-28             2             1
```



---

```{r child='closing_slide.Rmd'}

```
